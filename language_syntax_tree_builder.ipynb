{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pure Symbolic Approach – English\n",
    "(Adjectives are only prefixed to nouns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid parse found for the English sentence.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "\n",
    "# Define a simple CFG for English without inline comments.\n",
    "english_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DET N\n",
    "NP -> ADJ NP\n",
    "VP -> V NP\n",
    "VP -> V NP ADV\n",
    "DET -> 'the' | 'a'\n",
    "ADJ -> 'big' | 'small'\n",
    "N -> 'dog' | 'cat'\n",
    "V -> 'runs' | 'jumps'\n",
    "ADV -> 'quickly'\n",
    "\"\"\")\n",
    "\n",
    "# Sample sentence (tokenized)\n",
    "sentence = \"the big dog runs quickly\".split()\n",
    "\n",
    "# Create the parser and parse the sentence\n",
    "parser = ChartParser(english_grammar)\n",
    "parse_trees = list(parser.parse(sentence))\n",
    "\n",
    "if parse_trees:\n",
    "    print(\"English Parse Tree:\")\n",
    "    parse_trees[0].pretty_print()\n",
    "else:\n",
    "    print(\"No valid parse found for the English sentence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pure Symbolic Approach – French\n",
    "(Adjectives are only suffixed to nouns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid parse found for the French sentence.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "\n",
    "# Define a CFG for French with adjectives following the noun.\n",
    "french_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DET N\n",
    "NP -> NP ADJ\n",
    "VP -> V NP\n",
    "VP -> V NP ADV\n",
    "DET -> 'le' | 'la'\n",
    "ADJ -> 'grand' | 'petit'\n",
    "N -> 'chien' | 'chat'\n",
    "V -> 'court' | 'saute'\n",
    "ADV -> 'rapidement'\n",
    "\"\"\")\n",
    "\n",
    "# Sample French sentence (tokenized)\n",
    "sentence_fr = \"le chien grand court rapidement\".split()\n",
    "\n",
    "# Parse the French sentence\n",
    "parser_fr = ChartParser(french_grammar)\n",
    "parse_trees_fr = list(parser_fr.parse(sentence_fr))\n",
    "\n",
    "if parse_trees_fr:\n",
    "    print(\"French Parse Tree:\")\n",
    "    parse_trees_fr[0].pretty_print()\n",
    "else:\n",
    "    print(\"No valid parse found for the French sentence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pure Symbolic Approach – German\n",
    "(Adjectives are only prefixed to nouns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid parse found for the German sentence.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "\n",
    "# Define a CFG for German with adjectives preceding nouns.\n",
    "german_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DET N\n",
    "NP -> ADJ NP\n",
    "VP -> V NP\n",
    "VP -> V NP ADV\n",
    "DET -> 'der' | 'die'\n",
    "ADJ -> 'groß' | 'klein'\n",
    "N -> 'hund' | 'katze'\n",
    "V -> 'läuft' | 'springt'\n",
    "ADV -> 'schnell'\n",
    "\"\"\")\n",
    "\n",
    "# Sample German sentence (tokenized)\n",
    "sentence_de = \"der groß hund läuft schnell\".split()\n",
    "\n",
    "# Parse the German sentence\n",
    "parser_de = ChartParser(german_grammar)\n",
    "parse_trees_de = list(parser_de.parse(sentence_de))\n",
    "\n",
    "if parse_trees_de:\n",
    "    print(\"German Parse Tree:\")\n",
    "    parse_trees_de[0].pretty_print()\n",
    "else:\n",
    "    print(\"No valid parse found for the German sentence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pure Symbolic Approach – Italian\n",
    "(Adjectives are only suffixed to nouns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid parse found for the Italian sentence.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG, ChartParser\n",
    "\n",
    "# Define a CFG for Italian with adjectives following the noun.\n",
    "italian_grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DET N\n",
    "NP -> NP ADJ\n",
    "VP -> V NP\n",
    "VP -> V NP ADV\n",
    "DET -> 'il' | 'la'\n",
    "ADJ -> 'grande' | 'piccolo'\n",
    "N -> 'cane' | 'gatto'\n",
    "V -> 'corre' | 'salta'\n",
    "ADV -> 'velocemente'\n",
    "\"\"\")\n",
    "\n",
    "# Sample Italian sentence (tokenized)\n",
    "sentence_it = \"il cane grande corre velocemente\".split()\n",
    "\n",
    "# Parse the Italian sentence\n",
    "parser_it = ChartParser(italian_grammar)\n",
    "parse_trees_it = list(parser_it.parse(sentence_it))\n",
    "\n",
    "if parse_trees_it:\n",
    "    print(\"Italian Parse Tree:\")\n",
    "    parse_trees_it[0].pretty_print()\n",
    "else:\n",
    "    print(\"No valid parse found for the Italian sentence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Pure ML Approach – One-Step Markov Chain for POS Tagging\n",
    "(Training on the Brown corpus to forecast the next tag.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/majidtavakoli/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/majidtavakoli/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
      "Predicted POS Tag Sequence: ['DET', 'NOUN', '.', 'DET', 'NOUN', '.', 'DET', 'NOUN', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams, ConditionalFreqDist\n",
    "\n",
    "# Download necessary corpora (if not already downloaded)\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# Use the Brown corpus with a universal tagset.\n",
    "tagged_words = brown.tagged_words(tagset='universal')\n",
    "# Extract only the POS tags\n",
    "tags = [tag for (_, tag) in tagged_words]\n",
    "\n",
    "# Build tag bigrams and a conditional frequency distribution\n",
    "tag_bigrams = list(bigrams(tags))\n",
    "cfd = ConditionalFreqDist(tag_bigrams)\n",
    "\n",
    "def predict_next_tag(current_tag):\n",
    "    \"\"\"\n",
    "    Given a current POS tag, predict the most likely next tag.\n",
    "    \"\"\"\n",
    "    if current_tag in cfd:\n",
    "        return cfd[current_tag].max()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def predict_tag_sequence(sentence_tokens, start_tag='DET'):\n",
    "    \"\"\"\n",
    "    Predict a sequence of POS tags for the tokenized sentence using a one-step Markov chain.\n",
    "    The start_tag is provided (here assumed as 'DET' for demonstration).\n",
    "    \"\"\"\n",
    "    predicted_tags = [start_tag]\n",
    "    current_tag = start_tag\n",
    "    # For each subsequent token, use the most common successor tag.\n",
    "    for _ in range(1, len(sentence_tokens)):\n",
    "        next_tag = predict_next_tag(current_tag)\n",
    "        if not next_tag:\n",
    "            next_tag = start_tag\n",
    "        predicted_tags.append(next_tag)\n",
    "        current_tag = next_tag\n",
    "    return predicted_tags\n",
    "\n",
    "# Sample sentence (tokenized) for POS prediction.\n",
    "sentence_ml = \"the quick brown fox jumps over the lazy dog\".split()\n",
    "predicted_sequence = predict_tag_sequence(sentence_ml, start_tag='DET')\n",
    "\n",
    "print(\"Sentence:\", sentence_ml)\n",
    "print(\"Predicted POS Tag Sequence:\", predicted_sequence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
